{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig in by loading the data and starting our Exploratory Data Analysis (EDA) by inspecting the first few rows, to get a feeling for what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>...</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0047</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>20.0</td>\n",
       "      <td>489.05</td>\n",
       "      <td>604.13</td>\n",
       "      <td>1499.45</td>\n",
       "      <td>1309.95</td>\n",
       "      <td>10.52</td>\n",
       "      <td>...</td>\n",
       "      <td>372.15</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>8120.83</td>\n",
       "      <td>8.6216</td>\n",
       "      <td>0.03</td>\n",
       "      <td>368</td>\n",
       "      <td>2319</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>17.1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.13</td>\n",
       "      <td>1584.55</td>\n",
       "      <td>1403.96</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.81</td>\n",
       "      <td>2388.15</td>\n",
       "      <td>8132.87</td>\n",
       "      <td>8.3907</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.3619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.9986</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>60.0</td>\n",
       "      <td>449.44</td>\n",
       "      <td>555.42</td>\n",
       "      <td>1368.17</td>\n",
       "      <td>1122.49</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>183.26</td>\n",
       "      <td>2387.95</td>\n",
       "      <td>8063.84</td>\n",
       "      <td>9.3557</td>\n",
       "      <td>0.02</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.83</td>\n",
       "      <td>8.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0031</td>\n",
       "      <td>0.7005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>607.03</td>\n",
       "      <td>1488.44</td>\n",
       "      <td>1249.18</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>314.84</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8052.30</td>\n",
       "      <td>9.2231</td>\n",
       "      <td>0.02</td>\n",
       "      <td>364</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.42</td>\n",
       "      <td>14.7832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>42.0041</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>40.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.52</td>\n",
       "      <td>1354.48</td>\n",
       "      <td>1124.32</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>130.44</td>\n",
       "      <td>2387.89</td>\n",
       "      <td>8083.67</td>\n",
       "      <td>9.2986</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>6.4025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1    10.0047     0.2501       20.0  489.05  604.13   \n",
       "1        1            2     0.0015     0.0003      100.0  518.67  642.13   \n",
       "2        1            3    34.9986     0.8401       60.0  449.44  555.42   \n",
       "3        1            4    20.0031     0.7005        0.0  491.19  607.03   \n",
       "4        1            5    42.0041     0.8405       40.0  445.00  549.52   \n",
       "\n",
       "       s_3      s_4    s_5  ...    s_12     s_13     s_14    s_15  s_16  s_17  \\\n",
       "0  1499.45  1309.95  10.52  ...  372.15  2388.13  8120.83  8.6216  0.03   368   \n",
       "1  1584.55  1403.96  14.62  ...  521.81  2388.15  8132.87  8.3907  0.03   391   \n",
       "2  1368.17  1122.49   5.48  ...  183.26  2387.95  8063.84  9.3557  0.02   334   \n",
       "3  1488.44  1249.18   9.35  ...  314.84  2388.07  8052.30  9.2231  0.02   364   \n",
       "4  1354.48  1124.32   3.91  ...  130.44  2387.89  8083.67  9.2986  0.02   330   \n",
       "\n",
       "   s_18   s_19   s_20     s_21  \n",
       "0  2319  100.0  28.58  17.1735  \n",
       "1  2388  100.0  38.99  23.3619  \n",
       "2  2223  100.0  14.83   8.8555  \n",
       "3  2324  100.0  24.42  14.7832  \n",
       "4  2212  100.0  10.99   6.4025  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define filepath to read data\n",
    "dir_path = './Challenge_Data/'\n",
    "\n",
    "# define column names for easy indexing\n",
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1,22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "\n",
    "# read data\n",
    "train = pd.read_csv((dir_path+'train.txt'), sep='\\s+', header=None, names=col_names)\n",
    "test = pd.read_csv((dir_path+'test.txt'), sep='\\s+', header=None, names=col_names)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_limit = 922337203\n",
    "df = train\n",
    "grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "max_cycle = grouped_by_unit[\"time_cycles\"].max()\n",
    "\n",
    "# Merge the max cycle back into the original frame\n",
    "result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "\n",
    "# Calculate remaining useful life for each row\n",
    "remaining_useful_life = pd.Series([np.min([rul_limit, i]) for i in (result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]).tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  RUL\n",
       "0        1            1  130\n",
       "1        1            2  130\n",
       "2        1            3  130\n",
       "3        1            4  130\n",
       "4        1            5  130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_remaining_useful_life(df, rul_limit = 922337203):\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "    max_cycle = grouped_by_unit[\"time_cycles\"].max()\n",
    "    \n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)\n",
    "    \n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life = pd.Series([np.min([rul_limit, i]) for i in (result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]).tolist()])    \n",
    "    result_frame[\"RUL\"] = remaining_useful_life\n",
    "    \n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame\n",
    "\n",
    "train = add_remaining_useful_life(train, 130)\n",
    "train[index_names+['RUL']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster-wise Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def create_clusters(df):\n",
    "    model = pickle.load(open(\"kmeans_op.pkl\", \"rb\"))\n",
    "    preds = model.predict(df[['setting_1', 'setting_2', 'setting_3']])\n",
    "    tmp = df.copy()\n",
    "    tmp[\"OP\"] = pd.Series(preds)\n",
    "    tmp = tmp.drop(['setting_1', 'setting_2', 'setting_3'], axis=1)\n",
    "    return tmp\n",
    "\n",
    "def create_scalers(df): #should probably just give train split here\n",
    "    scaling_columns = ['s_1', 's_2', 's_3', 's_4', 's_5', 's_6',\n",
    "       's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15',\n",
    "       's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n",
    "    scalers = []\n",
    "    for i in range(6):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[df[\"OP\"] == i][scaling_columns])\n",
    "        scalers.append(scaler)\n",
    "    \n",
    "    return scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split_engines [  1   2   3   4   5   6   7   8   9  11  12  13  14  15  18  20  21  22\n",
      "  23  24  25  27  28  29  30  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  47  48  49  50  51  52  53  54  55  57  58  59  60  61  62\n",
      "  63  64  65  66  69  70  71  72  73  75  77  78  79  81  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  95  96  98  99 100 102 103 104 105 106\n",
      " 107 108 111 112 113 115 116 117 118 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 138 139 142 143 145 146 147 149 150 151 152\n",
      " 154 157 158 159 160 161 162 164 165 166 167 168 169 170 172 173 175 176\n",
      " 180 181 182 183 184 185 187 188 189 191 192 194 196 197 198 199 200 201\n",
      " 202 203 205 206 207 209 210 211 213 215 217 218] \n",
      "\n",
      "validate_split_engines [ 10  16  17  19  26  31  46  56  67  68  74  76  80  94  97 101 109 110\n",
      " 114 119 120 137 140 141 144 148 153 155 156 163 171 174 177 178 179 186\n",
      " 190 193 195 204 208 212 214 216] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "# eventhough we set np and tf seeds, gss requires its own seed\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.80, random_state=42)  \n",
    "\n",
    "def train_val_group_split(X, gss, groups, print_groups=True):\n",
    "    y = X.pop('RUL')\n",
    "    for idx_train, idx_val in gss.split(X, y, groups=groups):\n",
    "        if print_groups:\n",
    "            print('train_split_engines', train.iloc[idx_train]['unit_nr'].unique(), '\\n')\n",
    "            print('validate_split_engines', train.iloc[idx_val]['unit_nr'].unique(), '\\n')\n",
    "\n",
    "        X_train_split = X.iloc[idx_train].copy()\n",
    "        y_train_split = y.iloc[idx_train].copy()\n",
    "        X_val_split = X.iloc[idx_val].copy()\n",
    "        y_val_split = y.iloc[idx_val].copy()\n",
    "    return X_train_split, y_train_split, X_val_split, y_val_split\n",
    "train = create_clusters(train)\n",
    "split_result = train_val_group_split(train, gss, train['unit_nr'])\n",
    "X_train, y_train, X_val, y_val = split_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = create_scalers(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df, scalers):\n",
    "    scaling_columns = ['s_1', 's_2', 's_3', 's_4', 's_5', 's_6',\n",
    "       's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15',\n",
    "       's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n",
    "    new_x = []\n",
    "    for i in range(len(scalers)):\n",
    "        k = scalers[i].transform(df[df['OP'] == i][scaling_columns])\n",
    "        new_x.extend(k)\n",
    "        \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scale(X_train, scalers)\n",
    "X_val = scale(X_val, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_columns = ['s_1', 's_2', 's_3', 's_4', 's_5', 's_6',\n",
    "       's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15',\n",
    "       's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n",
    "X_train = pd.DataFrame(X_train, columns = scaling_columns)\n",
    "X_val = pd.DataFrame(X_val, columns = scaling_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import make_scorer\n",
    "def phm_Score(y_true, y_pred):\n",
    "    score = 0\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        if p >= t:\n",
    "            score+= math.exp(-(p-t)/13) - 1\n",
    "        else:\n",
    "            score+= math.exp(-(p-t)/10) - 1\n",
    "    return score/len(y_true)\n",
    "my_scorer = make_scorer(phm_Score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regression - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create an evaluate function\n",
    "def evaluate(y_true, y_hat, label='Test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# drop unwanted columns and split target variable from training set\n",
    "# drop_sensors = ['s_1','s_5','s_6','s_10','s_16','s_18','s_19']\n",
    "drop_labels = index_names\n",
    "\n",
    "train_s, val_s = split_engines(train)\n",
    "X_train = train_s.drop(drop_labels, axis=1)\n",
    "y_train = X_train.pop('RUL')\n",
    "\n",
    "X_val = val_s.drop(drop_labels, axis=1)\n",
    "y_val = X_val.pop('RUL')\n",
    "\n",
    "# Since the true RUL values for the test set are only provided for the last time cycle of each enginge, \n",
    "# the test set is subsetted to represent the same\n",
    "X_test = test.groupby('unit_nr').last().reset_index().drop(drop_labels, axis=1)\n",
    "\n",
    "\n",
    "print(X_train.columns)  # check remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, eta=0.1, gamma=0,\n",
       "             gpu_id=0, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.100000001, max_delta_step=0, max_depth=7,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=4, num_parallel_tree=1,\n",
       "             predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=0.7,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an xgboost regression model\n",
    "xgb_reg = xgboost.XGBRegressor(tree_method = \"gpu_hist\", predictor = \"gpu_predictor\", n_jobs = 4, verbosity = 1, n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "# evaluate model\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set RMSE:14.262043215197318, R2:0.8920525427568611\n",
      "Test set RMSE:46.239244704354235, R2:-0.13979151052867933\n"
     ]
    }
   ],
   "source": [
    "y_hat = xgb_reg.predict(X_val)\n",
    "y_train_pred = xgb_reg.predict(X_train)\n",
    "evaluate(y_train, y_train_pred, label = \"Train\")\n",
    "evaluate(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=6)]: Done 250 out of 250 | elapsed: 27.8min finished\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgboost.XGBRegressor(tree_method = \"gpu_hist\", predictor = \"gpu_predictor\", verbosity = 1,\n",
    "                           objective = \"reg:squarederror\")\n",
    "# Create parameter grid\n",
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "# Create RandomizedSearchCV Object\n",
    "xgb_rscv = RandomizedSearchCV(xgb_clf, param_distributions = parameters, scoring = my_scorer,\n",
    "                             cv = 5, verbose = 3, random_state = 42, n_jobs = 6, n_iter=50)\n",
    "\n",
    "# Fit the model\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-26.24195551649286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1650.5777052147805"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.01\n",
      "Gamma:  0.3\n",
      "Max Depth:  2\n",
      "Subsample:  0.4\n",
      "Max Features at Split:  0.8\n",
      "Alpha:  1\n",
      "Lamda:  4.5\n",
      "Minimum Sum of the Instance Weight Hessian to Make a Child:  3\n",
      "Number of Trees:  1000\n"
     ]
    }
   ],
   "source": [
    "# Model best estimators\n",
    "lr = model_xgboost.best_estimator_.get_params()[\"learning_rate\"]\n",
    "gam = model_xgboost.best_estimator_.get_params() [\"gamma\"]\n",
    "m_dep = model_xgboost.best_estimator_.get_params()[\"max_depth\"]\n",
    "sub_smp = model_xgboost.best_estimator_.get_params()[\"subsample\"]\n",
    "col_smp = model_xgboost.best_estimator_.get_params()[\"colsample_bytree\"]\n",
    "alp = model_xgboost.best_estimator_.get_params()[\"reg_alpha\"]\n",
    "lamb = model_xgboost.best_estimator_.get_params()[\"reg_lambda\"]\n",
    "m_chld_w = model_xgboost.best_estimator_.get_params()[\"min_child_weight\"]\n",
    "n_est = model_xgboost.best_estimator_.get_params()[\"n_estimators\"]\n",
    "print(\"Learning Rate: \", lr)\n",
    "print(\"Gamma: \", gam)\n",
    "print(\"Max Depth: \", m_dep)\n",
    "print(\"Subsample: \", sub_smp)\n",
    "print(\"Max Features at Split: \", col_smp)\n",
    "print(\"Alpha: \", alp)\n",
    "print(\"Lamda: \", lamb)\n",
    "print(\"Minimum Sum of the Instance Weight Hessian to Make a Child: \", m_chld_w)\n",
    "print(\"Number of Trees: \", n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we train with new params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=0,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.01, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=12, num_parallel_tree=1,\n",
       "             predictor='gpu_predictor', random_state=0, reg_alpha=1,\n",
       "             reg_lambda=4.5, scale_pos_weight=1, subsample=0.4,\n",
       "             tree_method='gpu_hist', validate_parameters=1, verbosity=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an xgboost regression model\n",
    "xgb_reg = xgboost.XGBRegressor(tree_method = \"gpu_hist\", predictor = \"gpu_predictor\", verbosity = 2, \n",
    "                               n_estimators=n_est, max_depth=m_dep, subsample=sub_smp, colsample_bytree=col_smp,\n",
    "                               learning_rate = lr, reg_alpha = alp, reg_lambda = lamb, min_child_weight = m_chld_w)\n",
    "# evaluate model\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set RMSE:43.079820110967816, R2:0.015089691655897464\n",
      "Test set RMSE:43.40700496342376, R2:-0.004439069360764547\n"
     ]
    }
   ],
   "source": [
    "y_hat = xgb_reg.predict(X_val)\n",
    "y_train_pred = xgb_reg.predict(X_train)\n",
    "evaluate(y_train, y_train_pred, label = \"Train\")\n",
    "evaluate(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 125,\n",
       " 124,\n",
       " 123,\n",
       " 122,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 118,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 113,\n",
       " 112,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 108,\n",
       " 107,\n",
       " 106,\n",
       " 105,\n",
       " 104,\n",
       " 103,\n",
       " 102,\n",
       " 101,\n",
       " 100,\n",
       " 99,\n",
       " 98,\n",
       " 97,\n",
       " 96,\n",
       " 95,\n",
       " 94,\n",
       " 93,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 81,\n",
       " 80,\n",
       " 79,\n",
       " 78,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 54,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 45,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 39,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 33,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 125,\n",
       " 124,\n",
       " 123,\n",
       " 122,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 118,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 113,\n",
       " 112,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 108,\n",
       " 107,\n",
       " 106,\n",
       " 105,\n",
       " 104,\n",
       " 103,\n",
       " 102,\n",
       " 101,\n",
       " 100,\n",
       " 99,\n",
       " 98,\n",
       " 97,\n",
       " 96,\n",
       " 95,\n",
       " 94,\n",
       " 93,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 81,\n",
       " 80,\n",
       " 79,\n",
       " 78,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 54,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 45,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 39,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 33,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 125,\n",
       " 124,\n",
       " 123,\n",
       " 122,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 118,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 113,\n",
       " 112,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 108,\n",
       " 107,\n",
       " 106,\n",
       " 105,\n",
       " 104,\n",
       " 103,\n",
       " 102,\n",
       " 101,\n",
       " 100,\n",
       " 99,\n",
       " 98,\n",
       " 97,\n",
       " 96,\n",
       " 95,\n",
       " 94,\n",
       " 93,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 81,\n",
       " 80,\n",
       " 79,\n",
       " 78,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 54,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 45,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 39,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 33,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 125,\n",
       " 124,\n",
       " 123,\n",
       " 122,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 118,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 113,\n",
       " 112,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 108,\n",
       " 107,\n",
       " 106,\n",
       " 105,\n",
       " 104,\n",
       " 103,\n",
       " 102,\n",
       " 101,\n",
       " 100,\n",
       " 99,\n",
       " 98,\n",
       " 97,\n",
       " 96,\n",
       " 95,\n",
       " 94,\n",
       " 93,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 81,\n",
       " 80,\n",
       " 79,\n",
       " 78,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 54,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 45,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 39,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 33,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 130,\n",
       " 129,\n",
       " 128,\n",
       " 127,\n",
       " 126,\n",
       " 125,\n",
       " 124,\n",
       " 123,\n",
       " 122,\n",
       " 121,\n",
       " 120,\n",
       " 119,\n",
       " 118,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 113,\n",
       " 112,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 108,\n",
       " 107,\n",
       " 106,\n",
       " 105,\n",
       " 104,\n",
       " 103,\n",
       " 102,\n",
       " 101,\n",
       " 100,\n",
       " 99,\n",
       " 98,\n",
       " 97,\n",
       " 96,\n",
       " 95,\n",
       " 94,\n",
       " 93,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 81,\n",
       " 80,\n",
       " 79,\n",
       " 78,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 74,\n",
       " 73,\n",
       " 72,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 67,\n",
       " 66,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 62,\n",
       " 61,\n",
       " 60,\n",
       " 59,\n",
       " 58,\n",
       " 57,\n",
       " 56,\n",
       " 55,\n",
       " 54,\n",
       " 53,\n",
       " 52,\n",
       " 51,\n",
       " 50,\n",
       " 49,\n",
       " 48,\n",
       " 47,\n",
       " 46,\n",
       " 45,\n",
       " 44,\n",
       " 43,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 39,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 34,\n",
       " 33,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 29,\n",
       " 28,\n",
       " 27,\n",
       " 26,\n",
       " 25,\n",
       " 24,\n",
       " 23,\n",
       " 22,\n",
       " 21,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 15,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb812e8cc8>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train.to_list()[:228])\n",
    "plt.plot(y_train_pred[:228])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got better poj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testpreproc(df, scalers):\n",
    "    df = create_clusters(df)\n",
    "    df = scale(df, scalers)\n",
    "    scaling_columns = ['s_1', 's_2', 's_3', 's_4', 's_5', 's_6',\n",
    "       's_7', 's_8', 's_9', 's_10', 's_11', 's_12', 's_13', 's_14', 's_15',\n",
    "       's_16', 's_17', 's_18', 's_19', 's_20', 's_21']\n",
    "    df = pd.DataFrame(df, columns = scaling_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_reg.predict(testpreproc(test, scalers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sub__01.txt\", 'w') as output:\n",
    "    for row in pred:\n",
    "        output.write(str(row) + '\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Site score for this solution -> 56572.3013642"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU_Enabled",
   "language": "python",
   "name": "tensorflow-gpu_enabled"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
